{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffd8747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root detected: C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ── Path setup ─────────────────────────────────────────────────────────────────\n",
    "# Run from repo root OR from notebooks/ folder — both work\n",
    "REPO_ROOT = os.path.abspath('..') if os.path.basename(os.getcwd()) == 'notebooks' else os.getcwd()\n",
    "DATA_PROC  = os.path.join(REPO_ROOT, 'data', 'processed')\n",
    "DATA_RAW   = os.path.join(REPO_ROOT, 'data', 'raw')\n",
    "DATA_HIST  = os.path.join(REPO_ROOT, 'data', 'history')\n",
    "\n",
    "print(f'Repo root detected: {REPO_ROOT}')\n",
    "\n",
    "# ── QA helper ─────────────────────────────────────────────────────────────────\n",
    "results = []   # accumulate all check results\n",
    "\n",
    "def qa(name, passed, detail=''):\n",
    "    status = '✅ PASS' if passed else '❌ FAIL'\n",
    "    results.append({'check': name, 'status': status, 'detail': detail})\n",
    "    print(f'  {status}  {name}' + (f' — {detail}' if detail else ''))\n",
    "\n",
    "def section(title):\n",
    "    print(f'\\n{\"=\"*60}\\n  {title}\\n{\"=\"*60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46451bb1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Processed Data Files (always available — committed to Git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c193e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  1A — manzanillo_training_data.csv\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\processed\\manzanillo_training_data.csv\n",
      "  Columns: ['UPMID', 'IDConglomerado', 'X_C3', 'Y_C3', 'Tipo_cgl_estandar_C3', 'Tipo_cgl_C3', 'Muestreado_C3', 'Anio_C3', 'Cve_Estado_C3', 'Estado_C3', 'Cve_Municipio_C3', 'Municipio_C3', 'CLAVE_UMAF_C3', 'UMAFOR_C3', 'CVE_S7_C3', 'DESCRIP_S7_C3', 'FORM_S7_C3', 'FAO_S7_C3', 'ECO_S7_C3', 'CVEECON1_C3', 'DESECON1_C3', 'CVEECON2_C3', 'DESECON2_C3', 'CVEECON3_C3', 'DESECON3_C3', 'CVEECON4_C3', 'DESECON4_C3', 'TIP_PROP_C3', 'TIP_NUC_C3', 'NUC_AGR_C3', 'CUENCA_19_C3', 'SUBCUEN_20_C3', 'ANP_CAT_DECRET_C3', 'ANP_CAT_MANEJO_C3', 'Tenencia_C3', 'Altitud_C3', 'Fisiografia_C3', 'Exposicion_C3', 'Con_sitio_1_C3', 'Con_sitio_2_C3', 'Con_sitio_3_C3', 'Con_sitio_4_C3', 'Sitios_x_cgl_C3', 'con_arbolado_C3', 'con_submuestra_C3', 'con_indicadores_condicion_copa_arbolado_C3', 'con_Veg_mayor_individual_C3', 'con_Veg_mayor_gregarios_C3', 'con_cobertura_1m2_C3', 'con_Veg_menor_zona_arida_C3', 'con_Suelo_C3', 'con_diversidad_de_epifitas_C3', 'con_parametros_físico_quimicos_C3', 'con_repoblado_C3', 'con_sotobosque_C3', 'Elevation_m', 'Slope_deg', 'UTM_X', 'UTM_Y', 'NDVI']\n",
      "  Shape:   (19, 60)\n",
      "  ✅ PASS  Row count > 10 — 19 rows — NOTE: only ~19 valid sites in Colima\n",
      "  ✅ PASS  No fully duplicate rows — 0 duplicates\n",
      "  ✅ PASS  Elevation_m: no nulls — 0 nulls\n",
      "  ✅ PASS  Slope_deg: no nulls — 0 nulls\n",
      "  ✅ PASS  NDVI: no nulls — 0 nulls\n",
      "  ✅ PASS  Latitudes in Colima range (18.5–20.0) — min=19.0014, max=19.4094\n",
      "  ✅ PASS  Longitudes in Colima range (-105.5 to -103.5) — min=-104.6279, max=-103.9601\n",
      "  ✅ PASS  NDVI values in valid range (-1 to 1) — min=0.159, max=0.670\n",
      "  ✅ PASS  Slope_deg in valid range (0–90°) — min=1.96, max=40.92\n",
      "\n",
      "Sample rows:\n",
      "   UPMID  Elevation_m  Slope_deg      NDVI       Y_C3        X_C3\n",
      "0  62281        874.0  17.180878  0.340968  19.138528 -103.960056\n",
      "1  65345       1103.0  17.023540  0.308824  19.273139 -104.057361\n",
      "2  66368       1489.0   5.884243  0.427851  19.318333 -104.010000\n",
      "3  62271        464.0   5.389372  0.418773  19.134111 -104.198306\n",
      "4  63305        922.0  30.452062  0.343653  19.183194 -104.008472\n"
     ]
    }
   ],
   "source": [
    "section('1A — manzanillo_training_data.csv')\n",
    "\n",
    "# Bounding box for Colima state (generous)\n",
    "LAT_MIN, LAT_MAX = 18.5, 20.0\n",
    "LON_MIN, LON_MAX = -105.5, -103.5\n",
    "\n",
    "path = os.path.join(DATA_PROC, 'manzanillo_training_data.csv')\n",
    "qa('File exists', os.path.exists(path), path)\n",
    "\n",
    "if os.path.exists(path):\n",
    "    df_train = pd.read_csv(path)\n",
    "    print(f'  Columns: {list(df_train.columns)}')\n",
    "    print(f'  Shape:   {df_train.shape}')\n",
    "\n",
    "    qa('Row count > 10', len(df_train) > 10, f'{len(df_train)} rows — NOTE: only ~19 valid sites in Colima')\n",
    "    qa('No fully duplicate rows', df_train.duplicated().sum() == 0, f'{df_train.duplicated().sum()} duplicates')\n",
    "\n",
    "    for col in ['Elevation_m', 'Slope_deg', 'NDVI']:\n",
    "        if col in df_train.columns:\n",
    "            n_null = df_train[col].isna().sum()\n",
    "            qa(f'{col}: no nulls', n_null == 0, f'{n_null} nulls')\n",
    "\n",
    "    # Coordinate sanity\n",
    "    lat_col = 'Y_C3' if 'Y_C3' in df_train.columns else ('Latitude' if 'Latitude' in df_train.columns else None)\n",
    "    lon_col = 'X_C3' if 'X_C3' in df_train.columns else ('Longitude' if 'Longitude' in df_train.columns else None)\n",
    "\n",
    "    if lat_col and lon_col:\n",
    "        lat_ok = df_train[lat_col].between(LAT_MIN, LAT_MAX).all()\n",
    "        lon_ok = df_train[lon_col].between(LON_MIN, LON_MAX).all()\n",
    "        qa('Latitudes in Colima range (18.5–20.0)', lat_ok,\n",
    "           f'min={df_train[lat_col].min():.4f}, max={df_train[lat_col].max():.4f}')\n",
    "        qa('Longitudes in Colima range (-105.5 to -103.5)', lon_ok,\n",
    "           f'min={df_train[lon_col].min():.4f}, max={df_train[lon_col].max():.4f}')\n",
    "\n",
    "    if 'NDVI' in df_train.columns:\n",
    "        ndvi_ok = df_train['NDVI'].between(-1, 1).all()\n",
    "        qa('NDVI values in valid range (-1 to 1)', ndvi_ok,\n",
    "           f'min={df_train[\"NDVI\"].min():.3f}, max={df_train[\"NDVI\"].max():.3f}')\n",
    "\n",
    "    if 'Slope_deg' in df_train.columns:\n",
    "        slope_ok = df_train['Slope_deg'].between(0, 90).all()\n",
    "        qa('Slope_deg in valid range (0–90°)', slope_ok,\n",
    "           f'min={df_train[\"Slope_deg\"].min():.2f}, max={df_train[\"Slope_deg\"].max():.2f}')\n",
    "\n",
    "    print('\\nSample rows:')\n",
    "    display_cols = [c for c in ['UPMID','Latitude','Longitude','Elevation_m','Slope_deg','NDVI','Y_C3','X_C3'] if c in df_train.columns]\n",
    "    print(df_train[display_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1df8e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  1B — manzanillo_FINAL_MODEL_DATA.csv\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\processed\\manzanillo_FINAL_MODEL_DATA.csv\n",
      "  Shape: (16, 7)\n",
      "  ✅ PASS  Row count > 10 — 16 rows — CRITICAL WARNING: < 20 rows means Random Forest is likely overfitted\n",
      "  ❌ FAIL  No extreme outliers in Fuel_Target (>1000) — 1 extreme values detected — check UPMID 59291 which shows 19875 in raw data\n",
      "              UPMID   Latitude   Longitude  Elevation_m  Slope_deg       NDVI  \\\n",
      "count     16.000000  16.000000   16.000000    16.000000  16.000000  16.000000   \n",
      "mean   64456.187500  19.233116 -104.051179   800.812500  23.290002   0.384135   \n",
      "std     2649.726985   0.118477    0.070705   318.535653  10.916446   0.117840   \n",
      "min    59291.000000  19.001417 -104.198306   280.000000   3.707287   0.159434   \n",
      "25%    62272.500000  19.135195 -104.070591   648.000000  16.831518   0.296445   \n",
      "50%    65346.000000  19.273153 -104.054013   720.500000  24.973383   0.383193   \n",
      "75%    66367.000000  19.318681 -104.010035   958.500000  28.944226   0.490789   \n",
      "max    68405.000000  19.409444 -103.961722  1465.000000  40.920765   0.570411   \n",
      "\n",
      "        Fuel_Target  \n",
      "count     16.000000  \n",
      "mean    1250.256665  \n",
      "std     4966.806224  \n",
      "min        5.580000  \n",
      "25%        7.682668  \n",
      "50%        8.474249  \n",
      "75%       10.034772  \n",
      "max    19875.778808  \n"
     ]
    }
   ],
   "source": [
    "section('1B — manzanillo_FINAL_MODEL_DATA.csv')\n",
    "\n",
    "path_final = os.path.join(DATA_PROC, 'manzanillo_FINAL_MODEL_DATA.csv')\n",
    "qa('File exists', os.path.exists(path_final), path_final)\n",
    "\n",
    "if os.path.exists(path_final):\n",
    "    df_model = pd.read_csv(path_final)\n",
    "    print(f'  Shape: {df_model.shape}')\n",
    "\n",
    "    qa('Row count > 10', len(df_model) > 10,\n",
    "       f'{len(df_model)} rows — CRITICAL WARNING: < 20 rows means Random Forest is likely overfitted')\n",
    "\n",
    "    if 'Fuel_Target' in df_model.columns:\n",
    "        ft = df_model['Fuel_Target']\n",
    "\n",
    "        # Anomalously large outlier visible in raw CSV\n",
    "        extreme = (ft > 1000).sum()\n",
    "        qa('No extreme outliers in Fuel_Target (>1000)', extreme == 0,\n",
    "           f'{extreme} extreme values detected — check UPMID 59291 which shows 19875 in raw data')\n",
    "\n",
    "    print(df_model.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3f9608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  1C — quantum_targets.csv\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\processed\\quantum_targets.csv\n",
      "  ✅ PASS  Row count == 50 — 50 rows\n",
      "  ✅ PASS  Risk_Score column present\n",
      "  ✅ PASS  Max Risk_Score == 100.0 — max=100.00\n",
      "  ✅ PASS  Target latitudes in Colima bounding box — min=18.7608, max=19.4871\n",
      "  ✅ PASS  Target longitudes in Colima bounding box — min=-104.0437, max=-103.6361\n"
     ]
    }
   ],
   "source": [
    "section('1C — quantum_targets.csv')\n",
    "\n",
    "path_qt = os.path.join(DATA_PROC, 'quantum_targets.csv')\n",
    "qa('File exists', os.path.exists(path_qt), path_qt)\n",
    "\n",
    "if os.path.exists(path_qt):\n",
    "    df_qt = pd.read_csv(path_qt)\n",
    "    qa('Row count == 50', len(df_qt) == 50, f'{len(df_qt)} rows')\n",
    "    qa('Risk_Score column present', 'Risk_Score' in df_qt.columns)\n",
    "    qa('Max Risk_Score == 100.0', abs(df_qt['Risk_Score'].max() - 100.0) < 0.01,\n",
    "       f'max={df_qt[\"Risk_Score\"].max():.2f}')\n",
    "\n",
    "    # COORDINATE ANOMALY CHECK — targets appear in wrong location\n",
    "    lat_ok = df_qt['Latitude'].between(LAT_MIN, LAT_MAX).all()\n",
    "    lon_ok = df_qt['Longitude'].between(LON_MIN, LON_MAX).all()\n",
    "    qa('Target latitudes in Colima bounding box', lat_ok,\n",
    "       f'min={df_qt[\"Latitude\"].min():.4f}, max={df_qt[\"Latitude\"].max():.4f}')\n",
    "    qa('Target longitudes in Colima bounding box', lon_ok,\n",
    "       f'min={df_qt[\"Longitude\"].min():.4f}, max={df_qt[\"Longitude\"].max():.4f}')\n",
    "\n",
    "    if not lon_ok:\n",
    "        print()\n",
    "        print('  ⚠️  ANOMALY DETECTED: Longitudes are ~-103.6 to -103.7.')\n",
    "        print('      The Manzanillo port is at ~-104.3. These targets appear ~70 km east of the port.')\n",
    "        print('      Likely cause: raster transform mismatch between DEM (INEGI) and Sentinel coordinate systems.')\n",
    "        print('      ACTION: Verify new_transform in notebook 05 — the sample_rate scaling may introduce offset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32925410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  1D — optimized_sensor_network.csv\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\processed\\optimized_sensor_network.csv\n",
      "  Shape: (25, 4)\n",
      "  Layers: {'Asset_Defense': 15, 'Wildland_Perimeter': 10}\n",
      "  ✅ PASS  Row count == 25 — 25 rows\n",
      "  ✅ PASS  No null coordinates\n",
      "  ✅ PASS  15 Asset_Defense sensors — 15\n",
      "  ✅ PASS  10 Wildland_Perimeter sensors — 10\n",
      "  ✅ PASS  Asset sensors within extended Zone A/B area — lat range: 19.0103–19.1018\n",
      "    latitude   longitude          layer sensor_id\n",
      "0  19.095880 -104.283001  Asset_Defense  Asset_00\n",
      "1  19.027243 -104.274907  Asset_Defense  Asset_01\n",
      "2  19.073800 -104.282905  Asset_Defense  Asset_02\n",
      "3  19.027595 -104.318755  Asset_Defense  Asset_03\n",
      "4  19.085413 -104.284007  Asset_Defense  Asset_04\n"
     ]
    }
   ],
   "source": [
    "section('1D — optimized_sensor_network.csv')\n",
    "\n",
    "path_sn = os.path.join(DATA_PROC, 'optimized_sensor_network.csv')\n",
    "qa('File exists', os.path.exists(path_sn), path_sn)\n",
    "\n",
    "# Config zones for bounding box check\n",
    "ZONE_A_LAT = (19.03, 19.10); ZONE_A_LON = (-104.35, -104.28)\n",
    "ZONE_B_LAT = (19.10, 19.18); ZONE_B_LON = (-104.30, -104.15)\n",
    "\n",
    "if os.path.exists(path_sn):\n",
    "    df_sn = pd.read_csv(path_sn)\n",
    "    print(f'  Shape: {df_sn.shape}')\n",
    "    print(f'  Layers: {df_sn[\"layer\"].value_counts().to_dict()}')\n",
    "\n",
    "    qa('Row count == 25', len(df_sn) == 25, f'{len(df_sn)} rows')\n",
    "    qa('No null coordinates', df_sn[['latitude','longitude']].isna().sum().sum() == 0)\n",
    "\n",
    "    asset_sensors = df_sn[df_sn['layer'] == 'Asset_Defense']\n",
    "    wild_sensors  = df_sn[df_sn['layer'] == 'Wildland_Perimeter']\n",
    "    qa('15 Asset_Defense sensors', len(asset_sensors) == 15, f'{len(asset_sensors)}')\n",
    "    qa('10 Wildland_Perimeter sensors', len(wild_sensors) == 10, f'{len(wild_sensors)}')\n",
    "\n",
    "    # Check sensors are near zones defined in config/zones.json\n",
    "    # Asset sensors should be near Zone A\n",
    "    asset_lat_ok = asset_sensors['latitude'].between(18.9, 19.2).all()\n",
    "    qa('Asset sensors within extended Zone A/B area', asset_lat_ok,\n",
    "       f'lat range: {asset_sensors[\"latitude\"].min():.4f}–{asset_sensors[\"latitude\"].max():.4f}')\n",
    "\n",
    "    print(df_sn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8368c944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  1E — sim_training_data.csv  (KNOWN MALFORMED ROWS)\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\history\\sim_training_data.csv\n",
      "  Expected columns from header: 7\n",
      "  Header: timestamp,wind_speed,wind_dir,start_x,start_y,damage_ha,growth_rate\n",
      "  ❌ FAIL  All rows have 7 columns — 23 malformed rows found\n",
      "  Malformed rows (line#, col_count, content):\n",
      "    Line 4: 8 cols — 2025-12-02T16:05:38.837004,6.4,239.0,945,557,6.0,265.5,44.25...\n",
      "    Line 5: 8 cols — 2025-12-02T16:06:05.396099,6.4,339.0,945,557,6.0,266.5,44.416666666666664...\n",
      "    Line 6: 8 cols — 2025-12-02T16:06:44.556953,6.4,339.0,945,557,6.0,264.5,44.083333333333336...\n",
      "    Line 7: 8 cols — 2025-12-02T16:06:49.918204,6.4,339.0,945,557,6.0,267.5,44.583333333333336...\n",
      "    Line 8: 8 cols — 2025-12-02T16:10:39.155105,6.0,338.0,945,557,6.0,270.0,45.0...\n",
      "    Line 9: 8 cols — 2025-12-02T16:10:55.090611,6.0,63.0,945,557,9.0,524.5,58.27777777777778...\n",
      "    Line 10: 8 cols — 2025-12-02T16:12:51.957919,6.0,232.0,945,557,6.0,276.0,46.0...\n",
      "    Line 11: 8 cols — 2025-12-02T16:13:07.092316,6.0,341.0,945,557,6.0,267.5,44.583333333333336...\n",
      "    Line 12: 8 cols — 2025-12-02T16:15:29.063590,6.0,232.0,793,683,6.0,258.0,43.0...\n",
      "    Line 13: 8 cols — 2025-12-02T20:34:42.827347,1.7,339.0,867,650,6.0,253.5,42.25...\n",
      "    Line 14: 8 cols — 2025-12-02T20:39:06.918291,1.7,339.0,867,650,6.0,258.0,43.0...\n",
      "    Line 15: 8 cols — 2025-12-02T20:41:47.503658,1.7,339.0,867,650,6.0,248.5,41.416666666666664...\n",
      "    Line 16: 8 cols — 2025-12-02T20:50:27.166929,1.8,354.0,867,650,6.0,252.0,42.0...\n",
      "    Line 17: 8 cols — 2025-12-02T21:06:59.734868,2.0,6.0,867,650,6.0,252.5,42.083333333333336...\n",
      "    Line 18: 8 cols — 2025-12-02T22:21:21.102760,2.3,31.0,867,650,6.0,254.5,42.416666666666664...\n",
      "    Line 19: 8 cols — 2025-12-02T23:08:10.878293,2.5,45,867,596,6,0.0225,0.00375...\n",
      "    Line 20: 5 cols — 2025-12-04T10:21:56.086513,5.0,19.06,0.0225,0.0...\n",
      "    Line 21: 5 cols — 2025-12-04T10:22:20.549769,2.0,19.05627684061726,0.0225,0.0...\n",
      "    Line 22: 5 cols — 2025-12-04T10:29:52.570846,5.0,19.06,0.0225,0.0...\n",
      "    Line 23: 5 cols — 2025-12-04T10:30:00.989773,5.0,19.06,0.0225,0.0...\n",
      "    Line 24: 5 cols — 2025-12-04T10:56:23.853963,5.0,19.06,0.0225,0.0...\n",
      "    Line 25: 6 cols — 2025-12-15 15:19:08.684016,6.5,243.0,19.04451300502649,-104.28214073181154,CONFI...\n",
      "    Line 26: 6 cols — 2025-12-15 15:19:15.685827,6.5,243.0,19.04451300502649,-104.28214073181154,CONFI...\n",
      "\n",
      "  Pandas read 9 rows after coercion (of 25 total)\n",
      "  ✅ PASS  pandas can read file — 9 rows successfully parsed\n"
     ]
    }
   ],
   "source": [
    "section('1E — sim_training_data.csv  (KNOWN MALFORMED ROWS)')\n",
    "\n",
    "path_sim = os.path.join(DATA_HIST, 'sim_training_data.csv')\n",
    "qa('File exists', os.path.exists(path_sim), path_sim)\n",
    "\n",
    "if os.path.exists(path_sim):\n",
    "    # Read raw lines to detect malformed rows\n",
    "    with open(path_sim) as f:\n",
    "        raw_lines = f.readlines()\n",
    "\n",
    "    header_cols = len(raw_lines[0].split(','))\n",
    "    print(f'  Expected columns from header: {header_cols}')\n",
    "    print(f'  Header: {raw_lines[0].strip()}')\n",
    "\n",
    "    malformed = []\n",
    "    for i, line in enumerate(raw_lines[1:], 2):\n",
    "        n_cols = len(line.split(','))\n",
    "        if n_cols != header_cols:\n",
    "            malformed.append((i, n_cols, line.strip()))\n",
    "\n",
    "    qa(f'All rows have {header_cols} columns', len(malformed) == 0,\n",
    "       f'{len(malformed)} malformed rows found')\n",
    "\n",
    "    if malformed:\n",
    "        print(f'  Malformed rows (line#, col_count, content):')\n",
    "        for m in malformed:\n",
    "            print(f'    Line {m[0]}: {m[1]} cols — {m[2][:80]}...')\n",
    "\n",
    "    # Try reading with pandas (it will coerce/drop malformed)\n",
    "    try:\n",
    "        df_sim = pd.read_csv(path_sim, on_bad_lines='warn')\n",
    "        print(f'\\n  Pandas read {len(df_sim)} rows after coercion (of {len(raw_lines)-1} total)')\n",
    "        qa('pandas can read file', True, f'{len(df_sim)} rows successfully parsed')\n",
    "    except Exception as e:\n",
    "        qa('pandas can read file', False, str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb062657",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Raw Data Source Checks\n",
    "These cells will SKIP gracefully if raw files are not present (they are gitignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1432bc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  2A — INEGI CEM DEM (Colima_r15m.tif)\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\raw\\inegi_cem\\Colima_r15m.tif\n",
      "  ✅ PASS  File opens without error\n",
      "  ✅ PASS  CRS is defined — EPSG:8999\n",
      "  ✅ PASS  Resolution ~ 0.000139° (15 m) — res=0.00013889\n",
      "  ✅ PASS  Has valid (>-1000) elevation values\n",
      "  ❌ FAIL  Elevation range reasonable (0–4000 m) — min=-8, max=32767\n",
      "  ✅ PASS  Bounds cover Colima state — left=-104.691, right=-103.486\n"
     ]
    }
   ],
   "source": [
    "section('2A — INEGI CEM DEM (Colima_r15m.tif)')\n",
    "\n",
    "inegi_path = os.path.join(DATA_RAW, 'inegi_cem', 'Colima_r15m.tif')\n",
    "qa('File exists', os.path.exists(inegi_path), inegi_path)\n",
    "\n",
    "if os.path.exists(inegi_path):\n",
    "    try:\n",
    "        import rasterio\n",
    "        with rasterio.open(inegi_path) as src:\n",
    "            qa('File opens without error', True)\n",
    "            qa('CRS is defined', src.crs is not None, str(src.crs))\n",
    "            qa('Resolution ~ 0.000139° (15 m)', abs(src.res[0] - 0.0001388889) < 0.00001,\n",
    "               f'res={src.res[0]:.8f}')\n",
    "\n",
    "            data = src.read(1)\n",
    "            valid = data[data > -1000]\n",
    "            qa('Has valid (>-1000) elevation values', len(valid) > 0)\n",
    "            qa('Elevation range reasonable (0–4000 m)', valid.min() >= 0 and valid.max() < 4000,\n",
    "               f'min={valid.min():.0f}, max={valid.max():.0f}')\n",
    "\n",
    "            bounds = src.bounds\n",
    "            qa('Bounds cover Colima state', bounds.left < -104 and bounds.right > -103.5,\n",
    "               f'left={bounds.left:.3f}, right={bounds.right:.3f}')\n",
    "\n",
    "    except ImportError:\n",
    "        print('  ⚠️  rasterio not installed — run: pip install rasterio')\n",
    "    except Exception as e:\n",
    "        qa('File opens without error', False, str(e))\n",
    "else:\n",
    "    print('  SKIP — raw file not present. Download from https://www.inegi.org.mx/app/geo2/elevacionesmex/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1386f26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  2B — Sentinel-2 ZIP (from data/raw/sentinel/)\n",
      "============================================================\n",
      "  ✅ PASS  sentinel/ directory exists\n",
      "  ✅ PASS  At least one .zip file present — 1 zips found\n",
      "  Using: S2C_MSIL2A_20260215T172411_N0512_R012_T13QEB_20260215T210013.SAFE.zip\n",
      "  ✅ PASS  File size > 0.5 GB (real Sentinel tile) — 1.13 GB\n",
      "  ✅ PASS  Band 4 (Red, 10m) present in ZIP — S2C_MSIL2A_20260215T172411_N0512_R012_T13QEB_20260215T210013.SAFE/GRANULE/L2A_T13QEB_A007561_20260215T172845/IMG_DATA/R10m/T13QEB_20260215T172411_B04_10m.jp2\n",
      "  ✅ PASS  Band 8 (NIR, 10m) present in ZIP — S2C_MSIL2A_20260215T172411_N0512_R012_T13QEB_20260215T210013.SAFE/GRANULE/L2A_T13QEB_A007561_20260215T172845/IMG_DATA/R10m/T13QEB_20260215T172411_B08_10m.jp2\n",
      "  ✅ PASS  Tile ID is 13QEB (Manzanillo) — filename: S2C_MSIL2A_20260215T172411_N0512_R012_T13QEB_20260215T210013.SAFE.zip\n"
     ]
    }
   ],
   "source": [
    "section('2B — Sentinel-2 ZIP (from data/raw/sentinel/)')\n",
    "\n",
    "sentinel_dir = os.path.join(DATA_RAW, 'sentinel')\n",
    "zip_files = []\n",
    "if os.path.exists(sentinel_dir):\n",
    "    zip_files = [f for f in os.listdir(sentinel_dir) if f.endswith('.zip')]\n",
    "\n",
    "qa('sentinel/ directory exists', os.path.exists(sentinel_dir))\n",
    "qa('At least one .zip file present', len(zip_files) > 0, f'{len(zip_files)} zips found')\n",
    "\n",
    "if zip_files:\n",
    "    import zipfile\n",
    "    zip_path = os.path.join(sentinel_dir, zip_files[0])\n",
    "    print(f'  Using: {zip_files[0]}')\n",
    "    file_size_gb = os.path.getsize(zip_path) / 1e9\n",
    "    qa('File size > 0.5 GB (real Sentinel tile)', file_size_gb > 0.5, f'{file_size_gb:.2f} GB')\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "            all_files = z.namelist()\n",
    "            red_files = [f for f in all_files if 'B04' in f and '10m' in f]\n",
    "            nir_files = [f for f in all_files if 'B08' in f and '10m' in f]\n",
    "            qa('Band 4 (Red, 10m) present in ZIP', len(red_files) > 0, red_files[0] if red_files else 'NOT FOUND')\n",
    "            qa('Band 8 (NIR, 10m) present in ZIP', len(nir_files) > 0, nir_files[0] if nir_files else 'NOT FOUND')\n",
    "            qa('Tile ID is 13QEB (Manzanillo)', '13QEB' in zip_files[0], f'filename: {zip_files[0]}')\n",
    "    except Exception as e:\n",
    "        qa('ZIP opens without error', False, str(e))\n",
    "else:\n",
    "    print('  SKIP — download from https://scihub.copernicus.eu — search Tile 13QEB, Sentinel-2 L2A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2602dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  2C — CONAFOR INFyS Excel\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\raw\\conafor_infys\\INFyS_2015_2020_Colima_qM0XXKR.xlsx\n",
      "  ✅ PASS  File readable by pandas — 74 rows\n",
      "  ✅ PASS  Row count > 50 — 74 rows\n",
      "  ✅ PASS  Y_C3 column present (latitude)\n",
      "  ✅ PASS  X_C3 column present (longitude)\n",
      "  ✅ PASS  UPMID column present (site ID)\n",
      "  ✅ PASS  Arbolado sheet readable — 2625 rows\n",
      "  ✅ PASS  Tree height (ALTURA_TOTAL) column present — AlturaTotal_C3\n",
      "  ✅ PASS  Has trees with positive height — 2625 valid trees\n"
     ]
    }
   ],
   "source": [
    "section('2C — CONAFOR INFyS Excel')\n",
    "\n",
    "conafor_path = os.path.join(DATA_RAW, 'conafor_infys', 'INFyS_2015_2020_Colima_qM0XXKR.xlsx')\n",
    "qa('File exists', os.path.exists(conafor_path), conafor_path)\n",
    "\n",
    "if os.path.exists(conafor_path):\n",
    "    try:\n",
    "        df_cnf = pd.read_excel(conafor_path)\n",
    "        qa('File readable by pandas', True, f'{len(df_cnf)} rows')\n",
    "        qa('Row count > 50', len(df_cnf) > 50, f'{len(df_cnf)} rows')\n",
    "        qa('Y_C3 column present (latitude)', 'Y_C3' in df_cnf.columns)\n",
    "        qa('X_C3 column present (longitude)', 'X_C3' in df_cnf.columns)\n",
    "        qa('UPMID column present (site ID)', 'UPMID' in df_cnf.columns)\n",
    "\n",
    "        # Arbolado sheet for tree height (Fuel_Target)\n",
    "        df_arb = pd.read_excel(conafor_path, sheet_name='Arbolado')\n",
    "        height_cols = [c for c in df_arb.columns if 'ALTURA' in str(c).upper() and 'TOTAL' in str(c).upper()]\n",
    "        qa('Arbolado sheet readable', True, f'{len(df_arb)} rows')\n",
    "        qa('Tree height (ALTURA_TOTAL) column present', len(height_cols) > 0,\n",
    "           height_cols[0] if height_cols else 'NOT FOUND')\n",
    "\n",
    "        if height_cols:\n",
    "            h_col = height_cols[0]\n",
    "            valid_trees = df_arb[df_arb[h_col] > 0]\n",
    "            qa('Has trees with positive height', len(valid_trees) > 0, f'{len(valid_trees)} valid trees')\n",
    "\n",
    "    except Exception as e:\n",
    "        qa('Excel file readable', False, str(e))\n",
    "else:\n",
    "    print('  SKIP — download from https://snmf.cnf.gob.mx/datos-del-inventario/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc0c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  2D — Live Open-Meteo API (Weather)\n",
      "============================================================\n",
      "  ✅ PASS  API returns 200 — status=200\n",
      "  ✅ PASS  wind_speed_10m present in response\n",
      "  ✅ PASS  wind_direction_10m present in response\n",
      "  ✅ PASS  Wind speed >= 0 kn — 1.4 kn\n",
      "  ✅ PASS  Wind direction 0–360° — 270°\n",
      "\n",
      "  Live weather at Manzanillo port: 1.4 kn from 270°\n"
     ]
    }
   ],
   "source": [
    "section('2D — Live Open-Meteo API (Weather)')\n",
    "\n",
    "PORT_LAT, PORT_LON = 19.052, -104.315\n",
    "\n",
    "try:\n",
    "    import requests\n",
    "    url = (f'https://api.open-meteo.com/v1/forecast?latitude={PORT_LAT}&longitude={PORT_LON}'\n",
    "           f'&current=wind_speed_10m,wind_direction_10m&wind_speed_unit=kn')\n",
    "    resp = requests.get(url, timeout=5)\n",
    "    qa('API returns 200', resp.status_code == 200, f'status={resp.status_code}')\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        data = resp.json()\n",
    "        current = data.get('current', {})\n",
    "        qa('wind_speed_10m present in response', 'wind_speed_10m' in current)\n",
    "        qa('wind_direction_10m present in response', 'wind_direction_10m' in current)\n",
    "\n",
    "        ws = current.get('wind_speed_10m', -1)\n",
    "        wd = current.get('wind_direction_10m', -1)\n",
    "        qa('Wind speed >= 0 kn', ws >= 0, f'{ws} kn')\n",
    "        qa('Wind direction 0–360°', 0 <= wd <= 360, f'{wd}°')\n",
    "        print(f'\\n  Live weather at Manzanillo port: {ws} kn from {wd}°')\n",
    "except requests.Timeout:\n",
    "    qa('API responds within 5 seconds', False, 'TIMEOUT — check network')\n",
    "except Exception as e:\n",
    "    qa('Open-Meteo API reachable', False, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b64d841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  2E — Trained Model File\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\models\\manzanillo_biomass_model.joblib\n",
      "  ✅ PASS  File size < 500 KB (sanity check) — 133.5 KB\n",
      "  ✅ PASS  Model loads without error\n",
      "  ✅ PASS  Has predict method\n",
      "  ✅ PASS  Model predicts on dummy input — prediction=6.75 m tree height\n",
      "  ✅ PASS  Prediction in plausible range (1–50 m) — 6.75 — if outside range, model may be overfitted\n",
      "  Feature importances: {'Elevation_m': np.float64(0.2277889084122654), 'Slope_deg': np.float64(0.14848420232438483), 'NDVI': np.float64(0.6237268892633497)}\n"
     ]
    }
   ],
   "source": [
    "section('2E — Trained Model File')\n",
    "\n",
    "model_path = os.path.join(REPO_ROOT, 'models', 'manzanillo_biomass_model.joblib')\n",
    "qa('File exists', os.path.exists(model_path), model_path)\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    size_kb = os.path.getsize(model_path) / 1024\n",
    "    qa('File size < 500 KB (sanity check)', size_kb < 500, f'{size_kb:.1f} KB')\n",
    "\n",
    "    try:\n",
    "        import joblib\n",
    "        model = joblib.load(model_path)\n",
    "        qa('Model loads without error', True)\n",
    "        qa('Has predict method', hasattr(model, 'predict'))\n",
    "\n",
    "        # Smoke test with dummy data\n",
    "        import pandas as pd\n",
    "        dummy = pd.DataFrame({'Elevation_m': [500.0], 'Slope_deg': [15.0], 'NDVI': [0.3]})\n",
    "        pred = model.predict(dummy)\n",
    "        qa('Model predicts on dummy input', len(pred) == 1, f'prediction={pred[0]:.2f} m tree height')\n",
    "        qa('Prediction in plausible range (1–50 m)', 1 <= pred[0] <= 50,\n",
    "           f'{pred[0]:.2f} — if outside range, model may be overfitted')\n",
    "\n",
    "        # Feature importances\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            fi = dict(zip(['Elevation_m','Slope_deg','NDVI'], model.feature_importances_))\n",
    "            print(f'  Feature importances: {fi}')\n",
    "    except Exception as e:\n",
    "        qa('Model loads without error', False, str(e))\n",
    "else:\n",
    "    print('  SKIP — model file not in repo. Re-run notebook 03 to regenerate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932b387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  2F — Road Network GraphML\n",
      "============================================================\n",
      "  ✅ PASS  File exists — C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\processed\\manzanillo_drive.graphml\n",
      "  ✅ PASS  File size 5–20 MB (sanity check) — 10.7 MB\n",
      "  ✅ PASS  Graph loads without error\n",
      "  ✅ PASS  Has > 100 nodes (not empty) — 9066 nodes, 23523 edges\n",
      "  ✅ PASS  Graph is connected (largest component > 90% of nodes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "section('2F — Road Network GraphML')\n",
    "\n",
    "graph_path = os.path.join(DATA_PROC, 'manzanillo_drive.graphml')\n",
    "qa('File exists', os.path.exists(graph_path), graph_path)\n",
    "\n",
    "if os.path.exists(graph_path):\n",
    "    size_mb = os.path.getsize(graph_path) / 1e6\n",
    "    qa('File size 5–20 MB (sanity check)', 5 <= size_mb <= 20, f'{size_mb:.1f} MB')\n",
    "\n",
    "    try:\n",
    "        G = ox.load_graphml(graph_path)\n",
    "        qa('Graph loads without error', True)\n",
    "        qa('Has > 100 nodes (not empty)', len(G.nodes) > 100, f'{len(G.nodes)} nodes, {len(G.edges)} edges')\n",
    "        \n",
    "        # Fix: wrap generator in parentheses and specify key=len\n",
    "        largest_cc = max(\n",
    "            (G.subgraph(c) for c in nx.weakly_connected_components(G)),\n",
    "            key=len\n",
    "        )\n",
    "        qa('Graph is connected (largest component > 90% of nodes)',\n",
    "           len(largest_cc.nodes) / len(G.nodes) > 0.9)\n",
    "    except ImportError:\n",
    "        print('  ⚠️  osmnx not installed — run: pip install osmnx')\n",
    "    except Exception as e:\n",
    "        qa('Graph loads without error', False, str(e))\n",
    "else:\n",
    "    print('  SKIP — regenerate by running: python rebuild_graph.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d4362",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Security Flags\n",
    "Items that must be addressed before any public sharing of this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "165f5c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  3 — Security & Credential Checks\n",
      "============================================================\n",
      "  ✅ PASS  No Earthdata username in notebook 00 output — ⚠️  USERNAME \"kingroyalfox\" FOUND IN COMMITTED NOTEBOOK OUTPUT — clear outputs before pushing\n",
      "  ✅ PASS  .dodsrc not present in repo\n",
      "  ✅ PASS  .gitignore covers data/raw/\n",
      "  ✅ PASS  .gitignore covers logs/\n",
      "  ✅ PASS  .gitignore covers __pycache__/\n"
     ]
    }
   ],
   "source": [
    "section('3 — Security & Credential Checks')\n",
    "\n",
    "# Check notebook 00 for exposed credentials\n",
    "nb00 = os.path.join(REPO_ROOT, 'notebooks', '00_Data_Acquisition.ipynb')\n",
    "if os.path.exists(nb00):\n",
    "    with open(nb00) as f:\n",
    "        content = f.read()\n",
    "    # Known exposed username from cell output\n",
    "    has_username = 'kingroyalfox' in content\n",
    "    qa('No Earthdata username in notebook 00 output', not has_username,\n",
    "       '⚠️  USERNAME \"kingroyalfox\" FOUND IN COMMITTED NOTEBOOK OUTPUT — clear outputs before pushing')\n",
    "\n",
    "# Check .dodsrc for credentials\n",
    "dodsrc = os.path.join(REPO_ROOT, 'notebooks', '.dodsrc')\n",
    "if os.path.exists(dodsrc):\n",
    "    qa('.dodsrc file not committed to repo',\n",
    "       False, '⚠️  .dodsrc contains cookie/netrc paths and is committed — add to .gitignore')\n",
    "else:\n",
    "    qa('.dodsrc not present in repo', True)\n",
    "\n",
    "# Check gitignore covers raw data\n",
    "gitignore = os.path.join(REPO_ROOT, '.gitignore')\n",
    "if os.path.exists(gitignore):\n",
    "    with open(gitignore) as f:\n",
    "        gi_content = f.read()\n",
    "    qa('.gitignore covers data/raw/', 'data/raw/' in gi_content)\n",
    "    qa('.gitignore covers logs/', 'logs/' in gi_content)\n",
    "    qa('.gitignore covers __pycache__/', '__pycache__/' in gi_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642445d",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. QA Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a4c6f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  QA SUMMARY\n",
      "============================================================\n",
      "Total checks: 71\n",
      "✅ Passed:    68\n",
      "❌ Failed:    3\n",
      "Score:        96%\n",
      "\n",
      "Failed checks:\n",
      "  ❌ No extreme outliers in Fuel_Target (>1000)\n",
      "     → 1 extreme values detected — check UPMID 59291 which shows 19875 in raw data\n",
      "  ❌ All rows have 7 columns\n",
      "     → 23 malformed rows found\n",
      "  ❌ Elevation range reasonable (0–4000 m)\n",
      "     → min=-8, max=32767\n",
      "\n",
      "Full results saved to: C:\\Users\\PhotonUser\\My Files\\OneDrive\\Files\\Manzanillo\\manzanillo-digital-twin\\data\\processed\\qa_results.csv\n"
     ]
    }
   ],
   "source": [
    "section('QA SUMMARY')\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "n_pass = (df_results['status'] == '✅ PASS').sum()\n",
    "n_fail = (df_results['status'] == '❌ FAIL').sum()\n",
    "total  = len(df_results)\n",
    "\n",
    "print(f'Total checks: {total}')\n",
    "print(f'✅ Passed:    {n_pass}')\n",
    "print(f'❌ Failed:    {n_fail}')\n",
    "print(f'Score:        {n_pass/total*100:.0f}%')\n",
    "print()\n",
    "\n",
    "if n_fail > 0:\n",
    "    print('Failed checks:')\n",
    "    fails = df_results[df_results['status'] == '❌ FAIL']\n",
    "    for _, row in fails.iterrows():\n",
    "        print(f'  ❌ {row[\"check\"]}')\n",
    "        if row['detail']:\n",
    "            print(f'     → {row[\"detail\"]}')\n",
    "\n",
    "# Save results\n",
    "out_path = os.path.join(REPO_ROOT, 'data', 'processed', 'qa_results.csv')\n",
    "df_results.to_csv(out_path, index=False)\n",
    "print(f'\\nFull results saved to: {out_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
